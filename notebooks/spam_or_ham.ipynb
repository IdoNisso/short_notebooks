{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam or Ham?\n",
    "\n",
    "## About\n",
    "A very simple Naive Bayes classifier of spam vs legit text messages. Dataset used for training is [SMS Spam Collection Dataset](https://www.kaggle.com/uciml/sms-spam-collection-dataset).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import kaggle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading sms-spam-collection-dataset.zip to ../datasets\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/208k [00:00<?, ?B/s]\n",
      "100%|##########| 208k/208k [00:00<00:00, 619kB/s]\n"
     ]
    }
   ],
   "source": [
    "# Downloading data\n",
    "!kaggle datasets download -p ../datasets --unzip uciml/sms-spam-collection-dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  (5572, 2) \n",
      "\n",
      "head: \n",
      "   target                                               text\n",
      "0    ham  Go until jurong point, crazy.. Available only ...\n",
      "1    ham                      Ok lar... Joking wif u oni...\n",
      "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3    ham  U dun say so early hor... U c already then say...\n",
      "4    ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "# Loading data\n",
    "spam_df = pd.read_csv('../datasets/spam.csv', encoding='latin-1')\n",
    "spam_df = spam_df.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1)\n",
    "spam_df = spam_df.rename(columns={\"v1\":\"target\", \"v2\":\"text\"})\n",
    "\n",
    "print('data shape: ', spam_df.shape, '\\n')\n",
    "print('head: \\n', spam_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     4825\n",
      "spam     747\n",
      "Name: target, dtype: int64 \n",
      "\n",
      "        text                                                               \n",
      "       count unique                                                top freq\n",
      "target                                                                     \n",
      "ham     4825   4516                             Sorry, I'll call later   30\n",
      "spam     747    653  Please call our customer service representativ...    4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (Very) Brief exploration\n",
    "print(spam_df.target.value_counts(), '\\n')\n",
    "print(spam_df.groupby(\"target\").describe(), '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing data\n",
    "def get_words(text):\n",
    "    \"\"\"Converts given text into unordered and uncounted bag of words.\"\"\"\n",
    "    return set(re.split('\\W+', text)).difference({''})\n",
    "\n",
    "spam_df['bag_of_words'] = [get_words(text) for text in spam_df.text]\n",
    "\n",
    "# Splitting into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(spam_df['bag_of_words'], spam_df['target'], \n",
    "                                                    test_size=0.2, random_state=42, stratify=spam_df['target'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Counters\n",
    "target_counter = Counter()\n",
    "word_counters = {\n",
    "    'spam': Counter(), \n",
    "    'ham': Counter()\n",
    "}\n",
    "all_words = set()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Naive Bayes classifier\n",
    "def prior_prob_of_target(target):\n",
    "    \"\"\"Evaluates probability of the given target ('spam' or 'ham') using the counters.\"\"\"\n",
    "    return target_counter[target] / sum(target_counter.values())\n",
    "\n",
    "def word_prob_given_target(word, target, pi=0.5, alpha=1e-6):\n",
    "    \"\"\"Calculates probability of a word occurence in the text, conditional on the target of text. \n",
    "    Adds a small constant to deal with out-of-dictionary cases.\"\"\"\n",
    "    return word_counters[target][word] / target_counter[target] * (1-alpha) + pi * alpha\n",
    "\n",
    "def text_prob_given_target(text, target):\n",
    "    \"\"\"Calculates probability of the text conditional on target.\"\"\"\n",
    "    if isinstance(text, str):\n",
    "        text = get_words(text)\n",
    "    prob = 1.0\n",
    "    for word in all_words:\n",
    "        if word in text:\n",
    "            prob *= word_prob_given_target(word, target)\n",
    "        else:\n",
    "            prob *= 1 - word_prob_given_target(word, target)\n",
    "    return prob\n",
    "\n",
    "def target_prob_given_text(text, target):\n",
    "    \"\"\"Calculates probability of the target (spam or ham) conditional on the text.\"\"\"\n",
    "    joint_probs = {\n",
    "        a_target: prior_prob_of_target(a_target) * text_prob_given_target(text, a_target)\n",
    "        for a_target in target_counter.keys()\n",
    "    }\n",
    "    \n",
    "    return joint_probs[target] / sum(joint_probs.values())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "for target, words in zip(y_train, X_train):\n",
    "    word_counters[target].update(words)\n",
    "    target_counter.update([target])\n",
    "    all_words.update(words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy:  0.9856502242152466\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "threshold = 0.5\n",
    "\n",
    "test_spam_probabilities = [target_prob_given_text(text, 'spam') for text in X_test]\n",
    "test_predictions = ['spam' if spamness > threshold else 'ham' for spamness in test_spam_probabilities]\n",
    "\n",
    "accuracy = sum(1 if y_pred == y_real else 0 for y_pred, y_real in zip(test_predictions, y_test)) / len(y_test)\n",
    "print('Test set accuracy: ', accuracy)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
