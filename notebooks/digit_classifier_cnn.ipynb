{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Digit Classifier\n",
    "\n",
    "## About\n",
    "Classify handwritten digits using a Convolutional Neural Network with Tensorflow mostly based on the [official TF CNN Tutorial](https://www.tensorflow.org/tutorials/estimators/cnn).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Stuff\\Installs\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining model\n",
    "def cnn_model_fn(features, labels, mode):\n",
    "    # Input Layer\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "    # Convolutional Layer #1\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=input_layer,\n",
    "        filters=32,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling Layer #1\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Convolutional Layer #2 and Pooling Layer #2\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=64,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Dense Layer\n",
    "    pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "    dropout = tf.layers.dropout(inputs=dense, rate=0.4, training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "\n",
    "    # Logits Layer\n",
    "    logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "\n",
    "    predictions = {\n",
    "        # Generate predictions (for PREDICT and EVAL mode)\n",
    "        \"classes\": tf.argmax(input=logits, axis=1),\n",
    "        # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "        # `logging_hook`.\n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\"accuracy\": tf.metrics.accuracy(labels=labels, predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and eval data\n",
    "((train_data, train_labels), (eval_data, eval_labels)) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_data = train_data/np.float32(255)\n",
    "train_labels = train_labels.astype(np.int32)\n",
    "\n",
    "eval_data = eval_data/np.float32(255)\n",
    "eval_labels = eval_labels.astype(np.int32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample image label:  7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b8c2b75b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check out sample image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "image_idx = 42\n",
    "print('Sample image label: ', train_labels[image_idx])\n",
    "plt.imshow(train_data[image_idx], cmap='Greys');\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001B8C5765C88>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Create the Estimator\n",
    "mnist_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn, model_dir=\"./model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging for predictions\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "\n",
    "logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Stuff\\Installs\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From D:\\Stuff\\Installs\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From D:\\Stuff\\Installs\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From <ipython-input-2-428b36a427da>:12: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "WARNING:tensorflow:From <ipython-input-2-428b36a427da>:15: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.max_pooling2d instead.\n",
      "WARNING:tensorflow:From <ipython-input-2-428b36a427da>:28: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From <ipython-input-2-428b36a427da>:29: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From D:\\Stuff\\Installs\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From D:\\Stuff\\Installs\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From D:\\Stuff\\Installs\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./model\\model.ckpt-1001\n",
      "WARNING:tensorflow:From D:\\Stuff\\Installs\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From D:\\Stuff\\Installs\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 1001 into ./model\\model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[0.09741112 0.09557429 0.08746302 0.1201653  0.11388905 0.06686622\n",
      "  0.0925846  0.10579817 0.10667181 0.11357643]\n",
      " [0.10095013 0.07650349 0.1146806  0.11158502 0.11442391 0.08306672\n",
      "  0.12973267 0.0648711  0.09627702 0.1079094 ]\n",
      " [0.17832248 0.03919855 0.10307626 0.12589705 0.07540776 0.0670732\n",
      "  0.13242957 0.06573205 0.10828322 0.10457988]\n",
      " [0.07115187 0.09944386 0.10191161 0.08600046 0.07498035 0.10418162\n",
      "  0.10049389 0.08743834 0.17096443 0.10343359]\n",
      " [0.08804837 0.09932751 0.09446046 0.09006225 0.11075562 0.10279906\n",
      "  0.13685508 0.08117652 0.09373434 0.10278083]\n",
      " [0.21051913 0.05406482 0.10900068 0.09046483 0.10611221 0.0910968\n",
      "  0.08340319 0.07504043 0.10692079 0.07337708]\n",
      " [0.07494327 0.11618342 0.10730165 0.14518827 0.06807863 0.09729509\n",
      "  0.08532209 0.09803442 0.1025264  0.10512669]\n",
      " [0.09108132 0.0880309  0.1564824  0.15711795 0.06760644 0.07711282\n",
      "  0.08739821 0.07624641 0.11390686 0.08501671]\n",
      " [0.12635253 0.08023151 0.10889174 0.10685017 0.06871665 0.11203002\n",
      "  0.09038971 0.07855926 0.09923314 0.12874517]\n",
      " [0.08256973 0.13023025 0.09518107 0.13349654 0.1196549  0.07282414\n",
      "  0.06686789 0.109527   0.09721547 0.092433  ]\n",
      " [0.0985771  0.11017761 0.12750018 0.10753427 0.08758955 0.07739271\n",
      "  0.11399175 0.05782689 0.12173484 0.09767509]\n",
      " [0.11109599 0.06469939 0.09609319 0.06923763 0.10167918 0.11177865\n",
      "  0.13390805 0.10210169 0.07144986 0.1379563 ]\n",
      " [0.05375895 0.19095951 0.0859311  0.09691462 0.05285161 0.08716229\n",
      "  0.09631279 0.11123379 0.10070832 0.12416704]\n",
      " [0.10864168 0.06147962 0.07174135 0.08661811 0.10503178 0.08103301\n",
      "  0.04609315 0.19221266 0.11627428 0.13087435]\n",
      " [0.28784907 0.04339194 0.09191435 0.12141096 0.04014326 0.07899091\n",
      "  0.13481747 0.05997207 0.10572645 0.03578354]\n",
      " [0.18159163 0.0456897  0.11179752 0.1324844  0.0802453  0.07776\n",
      "  0.10128046 0.08743577 0.08248536 0.0992298 ]\n",
      " [0.06514353 0.09826675 0.1030671  0.12011774 0.09713392 0.09277339\n",
      "  0.10702725 0.11010715 0.09637624 0.10998691]\n",
      " [0.14355254 0.04070975 0.11216114 0.09701672 0.08843011 0.08770076\n",
      "  0.15603536 0.05419176 0.15282872 0.06737316]\n",
      " [0.10283204 0.07429102 0.08484685 0.07634693 0.13890186 0.10677933\n",
      "  0.09190541 0.07608519 0.16472115 0.08329023]\n",
      " [0.11621197 0.05474413 0.11969855 0.1129087  0.09265765 0.11718272\n",
      "  0.11016683 0.09436594 0.09599762 0.08606586]\n",
      " [0.07707434 0.10003645 0.07046681 0.0993676  0.12469541 0.07687022\n",
      "  0.10700054 0.11452766 0.09993836 0.13002263]\n",
      " [0.19010791 0.0691     0.11751482 0.12850168 0.09429555 0.07646189\n",
      "  0.10620537 0.06847624 0.07700341 0.07233306]\n",
      " [0.10520786 0.08742882 0.10013257 0.12137631 0.08520687 0.09585654\n",
      "  0.10499587 0.10896555 0.11490178 0.0759278 ]\n",
      " [0.16863151 0.09617552 0.09412961 0.08180846 0.09683687 0.07395454\n",
      "  0.0721195  0.09030885 0.15391679 0.07211833]\n",
      " [0.17936216 0.06046677 0.07347491 0.11119414 0.06917981 0.05828637\n",
      "  0.10829511 0.12243169 0.12251679 0.09479224]\n",
      " [0.09299658 0.07643585 0.09535734 0.10043737 0.09984521 0.09543733\n",
      "  0.08317231 0.11492892 0.12426835 0.11712072]\n",
      " [0.08810534 0.10671191 0.18143208 0.14600618 0.04684242 0.07471983\n",
      "  0.06728201 0.07559045 0.12674908 0.0865607 ]\n",
      " [0.10142829 0.06483409 0.07198337 0.09982869 0.10746849 0.10087405\n",
      "  0.07687303 0.16369312 0.10133307 0.11168382]\n",
      " [0.08347789 0.08191347 0.080808   0.08704041 0.13485152 0.07003216\n",
      "  0.07248303 0.17195843 0.10057331 0.11686169]\n",
      " [0.14763118 0.07223742 0.18549016 0.09096161 0.11051825 0.06384318\n",
      "  0.11127929 0.05000921 0.10449978 0.06352994]\n",
      " [0.07553419 0.11699417 0.10821222 0.08351533 0.07333231 0.08001613\n",
      "  0.18634349 0.07257522 0.09073936 0.11273753]\n",
      " [0.07020368 0.11245929 0.08940747 0.12552565 0.07387537 0.07519718\n",
      "  0.08595595 0.10789278 0.12674168 0.13274096]\n",
      " [0.09950959 0.16977823 0.10692509 0.1068083  0.0515645  0.05776453\n",
      "  0.088773   0.0808348  0.10773969 0.13030227]\n",
      " [0.16552661 0.05921165 0.09856962 0.07502573 0.09726482 0.07916021\n",
      "  0.16510808 0.06229267 0.09931938 0.0985212 ]\n",
      " [0.08077755 0.08381369 0.06029569 0.09753677 0.13452485 0.06914767\n",
      "  0.05692512 0.13059467 0.13372071 0.1526633 ]\n",
      " [0.05278337 0.10066184 0.05838349 0.09355129 0.14228937 0.08744395\n",
      "  0.10165107 0.1187323  0.11001579 0.13448755]\n",
      " [0.29196113 0.0395974  0.11040653 0.10942867 0.05391125 0.07381392\n",
      "  0.08705562 0.07553266 0.10611144 0.05218137]\n",
      " [0.11867373 0.081133   0.12227366 0.1119715  0.09575377 0.10615753\n",
      "  0.11080818 0.07201907 0.11080922 0.07040038]\n",
      " [0.07136721 0.10752226 0.10222667 0.13594776 0.07793512 0.09916554\n",
      "  0.06453814 0.09235615 0.1189983  0.12994283]\n",
      " [0.16355878 0.07943837 0.09132002 0.10841233 0.0582534  0.07300176\n",
      "  0.10091272 0.08137826 0.1538406  0.08988374]\n",
      " [0.12396277 0.06768019 0.08703694 0.08705066 0.12767601 0.07572529\n",
      "  0.12717281 0.10090155 0.11197056 0.09082318]\n",
      " [0.10424161 0.06828554 0.11390515 0.0888475  0.07782685 0.08659505\n",
      "  0.21386215 0.05639228 0.10648072 0.08356313]\n",
      " [0.10244785 0.08392314 0.0734866  0.08507037 0.11284772 0.10515641\n",
      "  0.0987808  0.10950874 0.13546538 0.09331299]\n",
      " [0.06465542 0.10176979 0.06564401 0.08658965 0.13835484 0.08086373\n",
      "  0.07355141 0.14238328 0.10167498 0.14451288]\n",
      " [0.10766183 0.08885298 0.10275928 0.1434873  0.06541078 0.1006044\n",
      "  0.08639988 0.1092499  0.10546294 0.09011066]\n",
      " [0.12727018 0.0586363  0.1702195  0.15055099 0.07026604 0.08021919\n",
      "  0.1166584  0.06802645 0.09967887 0.05847408]\n",
      " [0.11341711 0.07524206 0.09909593 0.10061964 0.10447299 0.07548375\n",
      "  0.14031674 0.06218408 0.12137388 0.10779375]\n",
      " [0.10911722 0.07815769 0.0851113  0.07599456 0.10784081 0.10471582\n",
      "  0.06817361 0.13015148 0.13285396 0.10788353]\n",
      " [0.22315098 0.05110655 0.14505884 0.10637894 0.0748258  0.05345956\n",
      "  0.12929073 0.05975908 0.10303749 0.053932  ]\n",
      " [0.17713498 0.05739853 0.16691102 0.10039397 0.05109631 0.08005235\n",
      "  0.08574662 0.09842999 0.09141582 0.0914204 ]\n",
      " [0.081117   0.10129315 0.09364308 0.12555133 0.11738921 0.08029519\n",
      "  0.11481365 0.08254617 0.11968987 0.0836613 ]\n",
      " [0.09641732 0.08177394 0.09538881 0.08639174 0.07109801 0.0862077\n",
      "  0.10227995 0.14123036 0.17199408 0.06721813]\n",
      " [0.09696646 0.06752818 0.08497301 0.07475989 0.17245965 0.0818648\n",
      "  0.09288146 0.12219822 0.08364735 0.12272094]\n",
      " [0.09804934 0.0686231  0.1705743  0.10328151 0.0610054  0.09174539\n",
      "  0.11767081 0.07392808 0.12798753 0.08713455]\n",
      " [0.07739976 0.1141841  0.09998605 0.10784746 0.08217338 0.09392072\n",
      "  0.09541472 0.09851793 0.11627736 0.11427852]\n",
      " [0.11954304 0.04372063 0.08982228 0.15727226 0.06266808 0.10996503\n",
      "  0.10928396 0.07817827 0.1566442  0.0729022 ]\n",
      " [0.11907999 0.04800651 0.08753163 0.09409703 0.15622494 0.07404304\n",
      "  0.1116058  0.08213951 0.10549447 0.12177709]\n",
      " [0.09927982 0.10466236 0.08903787 0.11568849 0.08970923 0.08563724\n",
      "  0.08756328 0.10279649 0.09757345 0.12805174]\n",
      " [0.11133173 0.08453723 0.07099627 0.07282631 0.13170257 0.05942577\n",
      "  0.09000206 0.09916317 0.11084385 0.16917108]\n",
      " [0.11847118 0.06051067 0.11294274 0.08723038 0.13056883 0.09392586\n",
      "  0.13564824 0.07619783 0.10423424 0.08027002]\n",
      " [0.08452629 0.07998373 0.11740734 0.08579095 0.14030968 0.08031925\n",
      "  0.14567313 0.07241143 0.10312001 0.0904582 ]\n",
      " [0.07830601 0.06851672 0.07649316 0.17551334 0.07067612 0.14474031\n",
      "  0.08046624 0.08565431 0.13402182 0.08561196]\n",
      " [0.19210298 0.0517089  0.1093224  0.08665969 0.08634117 0.07691974\n",
      "  0.12485552 0.10921112 0.08497539 0.07790303]\n",
      " [0.08920424 0.0782081  0.08658496 0.09463202 0.13952853 0.07182678\n",
      "  0.11225589 0.09041733 0.1446731  0.0926691 ]\n",
      " [0.07818368 0.10731449 0.09459297 0.11567818 0.10236647 0.08080723\n",
      "  0.09923591 0.09165462 0.09323059 0.1369359 ]\n",
      " [0.06015148 0.14331701 0.16136529 0.12411721 0.07422805 0.0741808\n",
      "  0.09312361 0.08912997 0.10428818 0.07609839]\n",
      " [0.09261572 0.12681985 0.13636304 0.09426504 0.0968258  0.08520082\n",
      "  0.09665947 0.06636982 0.10180941 0.10307099]\n",
      " [0.08976167 0.06912225 0.12782541 0.14913797 0.06626166 0.11596812\n",
      "  0.08090065 0.09402033 0.10595772 0.1010442 ]\n",
      " [0.07454876 0.18849027 0.07509279 0.09638944 0.09801683 0.07280077\n",
      "  0.10294805 0.11046831 0.0934423  0.08780243]\n",
      " [0.09454972 0.08442315 0.07894645 0.1260309  0.1718966  0.06484522\n",
      "  0.10202642 0.08244297 0.08128787 0.11355075]\n",
      " [0.09549516 0.10648246 0.1287727  0.08902393 0.09957238 0.07491747\n",
      "  0.1469259  0.05249397 0.10176702 0.10454904]\n",
      " [0.08950952 0.10231947 0.08505901 0.10540049 0.10648777 0.0826375\n",
      "  0.0774505  0.10828979 0.14869957 0.09414627]\n",
      " [0.10891139 0.07077444 0.09887244 0.09083524 0.08102512 0.08535666\n",
      "  0.22096898 0.0619262  0.08656427 0.09476526]\n",
      " [0.13565664 0.06720891 0.10467437 0.1046294  0.09450728 0.08638026\n",
      "  0.07902119 0.12732148 0.12654535 0.07405514]\n",
      " [0.1681576  0.07114795 0.11944037 0.08659117 0.07947378 0.10073289\n",
      "  0.09811796 0.08340423 0.11326974 0.0796643 ]\n",
      " [0.07140974 0.13256645 0.09324636 0.09287396 0.12165401 0.08119071\n",
      "  0.08544794 0.08854508 0.10059275 0.132473  ]\n",
      " [0.0879181  0.11705758 0.08188187 0.10330272 0.08893287 0.08767253\n",
      "  0.11629468 0.08623066 0.09010864 0.14060032]\n",
      " [0.09576859 0.16464755 0.10678209 0.11536685 0.07834361 0.07683372\n",
      "  0.08294305 0.07128003 0.12881276 0.07922173]\n",
      " [0.06310316 0.17402206 0.09174654 0.10574288 0.08851682 0.05832052\n",
      "  0.10236485 0.08529137 0.10458065 0.12631111]\n",
      " [0.08147228 0.08124752 0.10262667 0.09345391 0.13431995 0.07382146\n",
      "  0.09452876 0.07490424 0.12259524 0.14103001]\n",
      " [0.09508359 0.07514192 0.11023964 0.11486921 0.06830736 0.11604909\n",
      "  0.0922857  0.08104382 0.14525536 0.10172427]\n",
      " [0.08383026 0.06827654 0.06926054 0.08290109 0.13893591 0.07866107\n",
      "  0.09801712 0.09141689 0.11618552 0.17251506]\n",
      " [0.08005269 0.09658749 0.08725317 0.11726828 0.11020548 0.07772471\n",
      "  0.1010671  0.08337405 0.13111892 0.11534807]\n",
      " [0.07786751 0.10079314 0.07373744 0.09250786 0.13449857 0.08249182\n",
      "  0.11510545 0.10324354 0.10559531 0.11415945]\n",
      " [0.13621393 0.14205268 0.09416401 0.09699499 0.08608089 0.06518944\n",
      "  0.10096088 0.06649291 0.14432827 0.06752203]\n",
      " [0.1371528  0.08105009 0.07634559 0.0794816  0.10545165 0.06864453\n",
      "  0.08717445 0.12777989 0.12694633 0.10997313]\n",
      " [0.08660366 0.0907483  0.10346135 0.14817548 0.06803901 0.09880594\n",
      "  0.10910527 0.07286819 0.12039948 0.1017933 ]\n",
      " [0.07357045 0.08714984 0.08325565 0.19077188 0.08270386 0.11155967\n",
      "  0.07633265 0.10400176 0.10817651 0.08247776]\n",
      " [0.07008441 0.16752878 0.08765033 0.09868754 0.07831275 0.0893445\n",
      "  0.10275861 0.08520591 0.0891731  0.13125405]\n",
      " [0.11497831 0.06634684 0.08666412 0.17091177 0.07232146 0.08769058\n",
      "  0.08641621 0.08326127 0.14107083 0.09033867]\n",
      " [0.09031276 0.06995229 0.08580145 0.12152094 0.11613341 0.09191678\n",
      "  0.1026853  0.11133983 0.07183783 0.13849936]\n",
      " [0.34955692 0.02857067 0.07425639 0.08922396 0.06407858 0.07350121\n",
      "  0.09794205 0.06559156 0.1054935  0.0517852 ]\n",
      " [0.12642813 0.07744608 0.09238496 0.10639184 0.10235938 0.0866535\n",
      "  0.1086835  0.08800408 0.10435437 0.10729415]\n",
      " [0.09471662 0.06714424 0.08672269 0.0979905  0.12551174 0.088618\n",
      "  0.08536489 0.10787406 0.08499151 0.16106574]\n",
      " [0.12358512 0.05808805 0.13244735 0.1609005  0.08014593 0.07968152\n",
      "  0.09358975 0.07662404 0.10532044 0.08961727]\n",
      " [0.10773965 0.07111032 0.0754447  0.05949943 0.14676988 0.10030656\n",
      "  0.11309753 0.0710073  0.1280763  0.12694834]\n",
      " [0.10682514 0.10227938 0.09833577 0.09265076 0.08988935 0.07919618\n",
      "  0.07731315 0.11751794 0.10820173 0.12779064]\n",
      " [0.11216598 0.08185513 0.10802401 0.10386854 0.08152759 0.09885016\n",
      "  0.10760205 0.09085156 0.11300209 0.10225286]\n",
      " [0.06364386 0.07613582 0.05828186 0.09466343 0.14673556 0.08192515\n",
      "  0.08755072 0.14371876 0.11483685 0.13250794]\n",
      " [0.09272663 0.10443512 0.07199387 0.08284263 0.10947039 0.08970471\n",
      "  0.10378007 0.12102612 0.10860819 0.11541222]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.9896094, step = 1001\n",
      "INFO:tensorflow:Saving checkpoints for 1002 into ./model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.9896094.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x1b8c545fd68>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": train_data},\n",
    "    y=train_labels,\n",
    "    batch_size=100,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "\n",
    "# train one step and display the probabilties\n",
    "mnist_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=1,\n",
    "    hooks=[logging_hook])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./model\\model.ckpt-1002\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1002 into ./model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1.9768846, step = 1002\n",
      "INFO:tensorflow:global_step/sec: 145.738\n",
      "INFO:tensorflow:loss = 1.792494, step = 1102 (0.687 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.722\n",
      "INFO:tensorflow:loss = 1.6198645, step = 1202 (0.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.245\n",
      "INFO:tensorflow:loss = 1.4896084, step = 1302 (0.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.685\n",
      "INFO:tensorflow:loss = 1.3052058, step = 1402 (0.622 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.903\n",
      "INFO:tensorflow:loss = 1.2581234, step = 1502 (0.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.037\n",
      "INFO:tensorflow:loss = 1.0832466, step = 1602 (0.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.302\n",
      "INFO:tensorflow:loss = 0.8856709, step = 1702 (0.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.943\n",
      "INFO:tensorflow:loss = 0.68888336, step = 1802 (0.622 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.654\n",
      "INFO:tensorflow:loss = 0.87725306, step = 1902 (0.634 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2002 into ./model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.77224946.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x1b8c545fd68>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_classifier.train(input_fn=train_input_fn, steps=1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-07-15T14:36:50Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./model\\model.ckpt-2002\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-07-15-14:36:51\n",
      "INFO:tensorflow:Saving dict for global step 2002: accuracy = 0.8531, global_step = 2002, loss = 0.63587254\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2002: ./model\\model.ckpt-2002\n",
      "{'accuracy': 0.8531, 'loss': 0.63587254, 'global_step': 2002}\n"
     ]
    }
   ],
   "source": [
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": eval_data},\n",
    "    y=eval_labels,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
